{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from random import sample\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import wide_resnet50_2, resnet18\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.image_files[idx]  # Renvoie l'image et son nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a new train file with just two classes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filepath)\n\u001b[0;32m      4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlat loop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yagoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\yagoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\yagoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\yagoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\yagoa\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "# Create a new train file with just two classes\n",
    "filepath = \"\"\n",
    "train_dataset = pd.read_csv(filepath)\n",
    "train_dataset = train_dataset.replace(\"GOOD\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Boucle plate\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Lift-off blanc\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Lift-off noir\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Short circuit MOS\", \"nm\")\n",
    "\n",
    "train_dataset.to_csv(\"modified_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(csv_file=\"/Users/nicolasthiou/Desktop/DataChallenge/Y_train_eVW9jym.csv\", root_dir=\"/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_train\", transform=transform, train=True)\n",
    "test_dataset = ImageDataset(csv_file=\"/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv\", root_dir=\"/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test\", transform=transform, train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier 1, decides if missing or not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train classifier 1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load Pretrained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "num_classes = 2\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_file1 = '/var/AI_Models_Training/TorchServe_essai/Benchmark_Challenge_ENS/Benoit/Version Finale/Classifier.pt'\n",
    "image_folder = '/var/AI_Models_Training/TorchServe_essai/Benchmark_Challenge_ENS/Benoit/Dataset/input_test'\n",
    "\n",
    "# Transformation des images pour l'entrée du modèle\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Chargement du dataset\n",
    "dataset = ImageDataset(image_folder, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# Load classifier model\n",
    "model = torch.load(classifier_file1)\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "# Passer les images dans le modèle\n",
    "y_pred_classifier1 = []\n",
    "filenames_list = []\n",
    "output_classifier=[]\n",
    "\n",
    "\n",
    "with torch.no_grad():  # Désactive le calcul des gradients\n",
    "    for images, filenames in dataloader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        # Move the outputs to CPU and convert to numpy\n",
    "        output_classifier.extend(outputs.cpu().numpy())\n",
    "        filenames_list.extend(filenames)  # Ajouter les noms de fichiers\n",
    "\n",
    "# Store scores and filenames\n",
    "for filename, score in zip(filenames_list, output_classifier):\n",
    "    y_pred_classifier1.append((filename, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier 2, decides the class if not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_file2 = '/var/AI_Models_Training/TorchServe_essai/Benchmark_Challenge_ENS/Benoit/Version Finale/Classifier.pt'\n",
    "image_folder = '/var/AI_Models_Training/TorchServe_essai/Benchmark_Challenge_ENS/Benoit/Dataset/input_test'\n",
    "\n",
    "# Transformation des images pour l'entrée du modèle\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Chargement du dataset\n",
    "dataset = ImageDataset(image_folder, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# Load classifier model\n",
    "model = torch.load(classifier_file1)\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "# Passer les images dans le modèle\n",
    "y_pred_classifier2 = []\n",
    "filenames_list = []\n",
    "output_classifier=[]\n",
    "\n",
    "\n",
    "with torch.no_grad():  # Désactive le calcul des gradients\n",
    "    for images, filenames in dataloader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        # Move the outputs to CPU and convert to numpy\n",
    "        output_classifier.extend(outputs.cpu().numpy())\n",
    "        filenames_list.extend(filenames)  # Ajouter les noms de fichiers\n",
    "\n",
    "# Store scores and filenames\n",
    "for filename, score in zip(filenames_list, output_classifier):\n",
    "    y_pred_classifier2.append((filename, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detector, again only if not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/var/AI_Models_Training/TorchServe_essai/Benchmark_Challenge_ENS/Benoit/Dataset/input_test'\n",
    "padim_trained = 'C:/Users/yagoa/Documents/MASH/Mallat/data_challenge/models_GXqjjM/PADIM.pkl'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "\n",
    "\n",
    "        for img_name in os.listdir(self.data_path):\n",
    "            img_path = os.path.join(self.data_path, img_name)\n",
    "            self.images.append(img_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Charger l'image\n",
    "    \n",
    "        # Appliquer les transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Appliquer les transformations à l'image\n",
    "\n",
    "        filename = os.path.basename(img_path)\n",
    "\n",
    "        return filename, image                               \n",
    "\n",
    "\n",
    "def denormalization(x):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (((x.transpose(1, 2, 0) * std) + mean) * 255.).astype(np.uint8)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def embedding_concat(x, y):\n",
    "    B, C1, H1, W1 = x.size()\n",
    "    _, C2, H2, W2 = y.size()\n",
    "    s = int(H1 / H2)\n",
    "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
    "    x = x.view(B, C1, -1, H2, W2)\n",
    "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2)\n",
    "    for i in range(x.size(2)):\n",
    "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
    "    z = z.view(B, -1, H2 * W2)\n",
    "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "# Charger les données d'entraînement\n",
    "with open(padim_trained, 'rb') as f:\n",
    "    train_outputs = pickle.load(f)\n",
    "\n",
    "model = wide_resnet50_2(pretrained=True, progress=True)\n",
    "t_d = 1792\n",
    "d = 550\n",
    "\n",
    "\n",
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "random.seed(1024)\n",
    "torch.manual_seed(1024)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(1024)\n",
    "\n",
    "idx = torch.tensor(sample(range(0, t_d), d))\n",
    "\n",
    "# set model's intermediate outputs\n",
    "outputs = []\n",
    "\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "model.layer1[-1].register_forward_hook(hook)\n",
    "model.layer2[-1].register_forward_hook(hook)\n",
    "model.layer3[-1].register_forward_hook(hook)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize((128, 128)),  # Redimensionner les images\n",
    "                                transforms.ToTensor(),            # Convertir en tenseur\n",
    "                                ])\n",
    "\n",
    "test_dataset = CustomDataset(test_path, transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, pin_memory=True)\n",
    "test_outputs = OrderedDict([('layer1', []), ('layer2', []), ('layer3', [])])\n",
    "\n",
    "test_imgs = []\n",
    "filenames_list = []\n",
    "scores_list = []\n",
    "\n",
    "# extract test set features\n",
    "for filename, x in tqdm(test_dataloader, '| feature extraction | test |'):\n",
    "    filenames_list.extend(filename)  # Collect filenames for the batch\n",
    "    test_imgs.extend(x.cpu().detach().numpy())\n",
    "    # model prediction\n",
    "    with torch.no_grad():\n",
    "        _ = model(x.to(device))\n",
    "    # get intermediate layer outputs\n",
    "    for k, v in zip(test_outputs.keys(), outputs):\n",
    "        test_outputs[k].append(v.cpu().detach())\n",
    "    # initialize hook outputs\n",
    "    outputs = []\n",
    "for k, v in test_outputs.items():\n",
    "    test_outputs[k] = torch.cat(v, 0)\n",
    "\n",
    "# Embedding concat\n",
    "embedding_vectors = test_outputs['layer1']\n",
    "for layer_name in ['layer2', 'layer3']:\n",
    "    embedding_vectors = embedding_concat(embedding_vectors, test_outputs[layer_name])\n",
    "\n",
    "# randomly select d dimension\n",
    "embedding_vectors = torch.index_select(embedding_vectors, 1, idx)\n",
    "\n",
    "# calculate distance matrix\n",
    "B, C, H, W = embedding_vectors.size()\n",
    "embedding_vectors = embedding_vectors.view(B, C, H * W).numpy()\n",
    "dist_list = []\n",
    "for i in range(H * W):\n",
    "    mean = train_outputs[0][:, i]\n",
    "    conv_inv = np.linalg.inv(train_outputs[1][:, :, i])\n",
    "    dist = [mahalanobis(sample[:, i], mean, conv_inv) for sample in embedding_vectors]\n",
    "    dist_list.append(dist)\n",
    "\n",
    "dist_list = np.array(dist_list).transpose(1, 0).reshape(B, H, W)\n",
    "\n",
    "# upsample\n",
    "dist_list = torch.tensor(dist_list)\n",
    "score_map = F.interpolate(dist_list.unsqueeze(1), size=x.size(2), mode='bilinear',\n",
    "                            align_corners=False).squeeze().numpy()\n",
    "\n",
    "# apply gaussian smoothing on the score map\n",
    "for i in range(score_map.shape[0]):\n",
    "    score_map[i] = gaussian_filter(score_map[i], sigma=4)\n",
    "\n",
    "# Normalization\n",
    "max_score = score_map.max()\n",
    "min_score = score_map.min()\n",
    "scores = (score_map - min_score) / (max_score - min_score)\n",
    "\n",
    "# calculate image-level ROC AUC score\n",
    "img_scores = scores.reshape(scores.shape[0], -1).max(axis=1)\n",
    "\n",
    "# Store scores and filenames\n",
    "for filename, score in zip(filenames_list, img_scores):\n",
    "    scores_list.append((filename, score))\n",
    "    \n",
    "y_pred_anomaly = scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir y_pred_anomaly en un dictionnaire\n",
    "anomaly_dict = dict(y_pred_anomaly)\n",
    "\n",
    "# Convertir y_pred_classifier en un dictionnaire\n",
    "classifier_dict1 = dict(y_pred_classifier1)\n",
    "classifier_dict2 = dict(y_pred_classifier2)\n",
    "\n",
    "# Fusionner les deux dictionnaires basés sur le filename\n",
    "# Assurer que tous les filenames sont présents dans les deux modèles\n",
    "merged_data = []\n",
    "for filename in anomaly_dict.keys():\n",
    "    if filename in classifier_dict2 and filename in classifier_dict1:\n",
    "        anomaly_score = anomaly_dict[filename]\n",
    "        classifier_probs2 = classifier_dict2[filename]\n",
    "        classifier_probs1 = classifier_dict1[filename]\n",
    "        merged_data.append((filename, anomaly_score, *classifier_probs1, *classifier_probs2))  # Fusionner les données\n",
    "        \n",
    "\n",
    "# Créer un DataFrame pandas avec les résultats\n",
    "final_df = pd.DataFrame(merged_data, columns=['filename', 'p_drift', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p_missing'])\n",
    "\n",
    "merged_df = pd.merge(final_df, test_df, on='filename', how='inner')\n",
    "\n",
    "def define_classe(row, threshold=0.5):\n",
    "    p_missing = row['p_missing']\n",
    "    # Accéder à la valeur de p_drift dans la ligne\n",
    "    p_drift = row['p_drift']\n",
    "    \n",
    "    # Extraire les probabilités des classes (colonnes 2 à 7)\n",
    "    p_classes = row[['p0', 'p1', 'p2', 'p3', 'p4', 'p5']].values\n",
    "    \n",
    "    if p_missing > 0.6:\n",
    "        return 4\n",
    "    if p_drift > threshold:\n",
    "        return 6\n",
    "    else:\n",
    "        return p_classes.argmax()  # Utiliser argmax pour obtenir l'indice du max\n",
    "\n",
    "# Appliquer la fonction à chaque ligne du DataFrame\n",
    "merged_df['y_pred'] = merged_df.apply(define_classe, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
