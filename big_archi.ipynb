{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from random import sample\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import wide_resnet50_2, resnet18\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, train=True):\n",
    "        self.data = pd.read_csv(csv_file)  # Load CSV file\n",
    "        self.root_dir = root_dir           # Directory where images are stored\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        \n",
    "        # Create a label-to-integer mapping\n",
    "        self.label_map = {label: idx for idx, label in enumerate(self.data.iloc[:, -1].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 1])  # 2nd column is filename\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.train:\n",
    "            label = self.data.iloc[idx, -1]  # Last column is the label\n",
    "            \n",
    "            # Convert the text label to an integer label\n",
    "            label = self.label_map.get(label, -1)  # -1 if the label is not found, you can handle it differently\n",
    "            label = torch.tensor(label, dtype=torch.long)  # Convert to tensor\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetFilename(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, train=True):\n",
    "        self.data = pd.read_csv(csv_file)  # Load CSV file\n",
    "        self.root_dir = root_dir           # Directory where images are stored\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        \n",
    "        # Create a label-to-integer mapping\n",
    "        self.label_map = {label: idx for idx, label in enumerate(self.data.iloc[:, -1].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 1])  # 2nd column is filename\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.train:\n",
    "            label = self.data.iloc[idx, -1]  # Last column is the label\n",
    "            \n",
    "            # Convert the text label to an integer label\n",
    "            label = self.label_map.get(label, -1)  # -1 if the label is not found, you can handle it differently\n",
    "            label = torch.tensor(label, dtype=torch.long)  # Convert to tensor\n",
    "            return image, label\n",
    "        else:\n",
    "            return image,img_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new train file with just two classes\n",
    "filepath = \"/Users/nicolasthiou/Desktop/DataChallenge/Y_train_eVW9jym.csv\"\n",
    "train_dataset = pd.read_csv(filepath)\n",
    "train_dataset = train_dataset.replace(\"GOOD\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Boucle plate\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Lift-off noir\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Lift-off blanc\", \"nm\")\n",
    "train_dataset =train_dataset.replace(\"Short circuit MOS\", \"nm\")\n",
    "\n",
    "train_dataset.to_csv(\"modified_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(csv_file=\"/Users/nicolasthiou/Desktop/DataChallenge/Y_train_eVW9jym.csv\", root_dir=\"/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_train\", transform=transform, train=True)\n",
    "test_dataset = ImageDataset(csv_file=\"/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv\", root_dir=\"/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test\", transform=transform, train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier 1, decides if missing or not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasthiou/miniconda3/envs/STMC/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nicolasthiou/miniconda3/envs/STMC/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 259/259 [01:08<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:09<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:10<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:10<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:12<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:11<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:10<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:10<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:10<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:10<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:11<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:11<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:12<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:12<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:12<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:11<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:12<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:11<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:13<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [01:11<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0031\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Train classifier 1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load Pretrained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "num_classes = 2\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to MissingOrNot.pth\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Save the model\n",
    "# Save the trained model\n",
    "model_name = 'MissingOrNot'\n",
    "model_save_path = 'MissingOrNot.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_mapping': train_dataset.label_map,\n",
    "    'model_name': model_name,\n",
    "}, model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/nrjdn0dn3s56bt4jf41m2rcc0000gn/T/ipykernel_44638/2775736986.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(classifier_file1, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions and probabilities saved\n"
     ]
    }
   ],
   "source": [
    "classifier_file1 = '/Users/nicolasthiou/Desktop/DataChallenge/data_challenge/MissingOrNot.pth'\n",
    "image_folder = '/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test'\n",
    "\n",
    "# Transformation des images pour l'entrée du modèle\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Chargement du dataset\n",
    "dataset = ImageDatasetFilename(csv_file=\"/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv\", root_dir=\"/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test\", transform=transform, train=False)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('mps')\n",
    "num_classes = 2  # Set this to match your training setup\n",
    "model = models.resnet50()\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=num_classes)  # Match trained model\n",
    "\n",
    "# Load the saved dictionary\n",
    "checkpoint = torch.load(classifier_file1, map_location=device)\n",
    "\n",
    "# Load model state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Apply softmax to get class probabilities\n",
    "        probs = F.softmax(outputs, dim=1)  # probs is a tensor with shape [batch_size, num_classes]\n",
    "        \n",
    "        # Get predicted class (index of maximum probability)\n",
    "        _, preds = torch.max(probs, 1)  # Get the class index with highest probability\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())  # Convert predictions to numpy and append\n",
    "        probabilities.extend(probs.cpu().numpy())  # Append probabilities as well\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "import pandas as pd\n",
    "\n",
    "test_filenames = pd.read_csv(\"/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv\").iloc[:, 1]  # Get filenames from the test CSV\n",
    "\n",
    "# Create a DataFrame for predictions with probabilities\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": test_filenames,\n",
    "    \"label\": predictions,\n",
    "    \"probabilities\": [prob.tolist()[0] for prob in probabilities]  # Convert each prob tensor to a list\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"PRED1.csv\", index=False)\n",
    "\n",
    "print(\"Predictions and probabilities saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier 2, decides the class if not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/nrjdn0dn3s56bt4jf41m2rcc0000gn/T/ipykernel_44638/1511014312.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(classifier_file2, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions and probabilities saved\n"
     ]
    }
   ],
   "source": [
    "classifier_file2 = '/Users/nicolasthiou/Desktop/DataChallenge/data_challenge/image_classifier_model_bis.pth'\n",
    "image_folder = '/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test'\n",
    "\n",
    "# Transformation des images pour l'entrée du modèle\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Chargement du dataset\n",
    "dataset = ImageDatasetFilename(csv_file=\"/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv\", root_dir=\"/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test\", transform=transform, train=False)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('mps')\n",
    "num_classes = 6  # Set this to match your training setup\n",
    "model = models.resnet50()\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=num_classes)  # Match trained model\n",
    "\n",
    "# Load the saved dictionary\n",
    "checkpoint = torch.load(classifier_file2, map_location=device)\n",
    "\n",
    "# Load model state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Apply softmax to get class probabilities\n",
    "        probs = F.softmax(outputs, dim=1)  # probs is a tensor with shape [batch_size, num_classes]\n",
    "        \n",
    "        # Get predicted class (index of maximum probability)\n",
    "        _, preds = torch.max(probs, 1)  # Get the class index with highest probability\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())  # Convert predictions to numpy and append\n",
    "        probabilities.extend(probs.cpu().numpy())  # Append probabilities as well\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "import pandas as pd\n",
    "\n",
    "test_filenames = pd.read_csv(\"/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv\").iloc[:, 1]  # Get filenames from the test CSV\n",
    "\n",
    "# Create a DataFrame for predictions with probabilities\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": test_filenames,\n",
    "    \"label\": predictions,\n",
    "    \"probabilities\": [prob.tolist() for prob in probabilities]  # Convert each prob tensor to a list\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"PRED2.csv\", index=False)\n",
    "\n",
    "print(\"Predictions and probabilities saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detector, again only if not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasthiou/miniconda3/envs/STMC/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nicolasthiou/miniconda3/envs/STMC/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "| feature extraction | test |: 100%|██████████| 33/33 [00:02<00:00, 11.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path =  '/Users/nicolasthiou/Desktop/DataChallenge/preprocessed_test'\n",
    "padim_trained = '/Users/nicolasthiou/Desktop/DataChallenge/models_GX6qjjM/PADIM.pkl'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "\n",
    "\n",
    "        for img_name in os.listdir(self.data_path):\n",
    "            img_path = os.path.join(self.data_path, img_name)\n",
    "            self.images.append(img_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Charger l'image\n",
    "    \n",
    "        # Appliquer les transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Appliquer les transformations à l'image\n",
    "\n",
    "        filename = os.path.basename(img_path)\n",
    "\n",
    "        return filename, image                               \n",
    "\n",
    "\n",
    "def denormalization(x):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (((x.transpose(1, 2, 0) * std) + mean) * 255.).astype(np.uint8)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def embedding_concat(x, y):\n",
    "    B, C1, H1, W1 = x.size()\n",
    "    _, C2, H2, W2 = y.size()\n",
    "    s = int(H1 / H2)\n",
    "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
    "    x = x.view(B, C1, -1, H2, W2)\n",
    "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2)\n",
    "    for i in range(x.size(2)):\n",
    "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
    "    z = z.view(B, -1, H2 * W2)\n",
    "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "# Charger les données d'entraînement\n",
    "with open(padim_trained, 'rb') as f:\n",
    "    train_outputs = pickle.load(f)\n",
    "\n",
    "model = wide_resnet50_2(pretrained=True, progress=True)\n",
    "t_d = 1792\n",
    "d = 550\n",
    "\n",
    "\n",
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('mps')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "random.seed(1024)\n",
    "torch.manual_seed(1024)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(1024)\n",
    "\n",
    "idx = torch.tensor(sample(range(0, t_d), d))\n",
    "\n",
    "# set model's intermediate outputs\n",
    "outputs = []\n",
    "\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "model.layer1[-1].register_forward_hook(hook)\n",
    "model.layer2[-1].register_forward_hook(hook)\n",
    "model.layer3[-1].register_forward_hook(hook)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize((128, 128)),  # Redimensionner les images\n",
    "                                transforms.ToTensor(),            # Convertir en tenseur\n",
    "                                ])\n",
    "\n",
    "test_dataset = CustomDataset(test_path, transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, pin_memory=True)\n",
    "test_outputs = OrderedDict([('layer1', []), ('layer2', []), ('layer3', [])])\n",
    "\n",
    "test_imgs = []\n",
    "filenames_list = []\n",
    "scores_list = []\n",
    "\n",
    "# extract test set features\n",
    "for filename, x in tqdm(test_dataloader, '| feature extraction | test |'):\n",
    "    filenames_list.extend(filename)  # Collect filenames for the batch\n",
    "    test_imgs.extend(x.cpu().detach().numpy())\n",
    "    # model prediction\n",
    "    with torch.no_grad():\n",
    "        _ = model(x.to(device))\n",
    "    # get intermediate layer outputs\n",
    "    for k, v in zip(test_outputs.keys(), outputs):\n",
    "        test_outputs[k].append(v.cpu().detach())\n",
    "    # initialize hook outputs\n",
    "    outputs = []\n",
    "for k, v in test_outputs.items():\n",
    "    test_outputs[k] = torch.cat(v, 0)\n",
    "\n",
    "# Embedding concat\n",
    "embedding_vectors = test_outputs['layer1']\n",
    "for layer_name in ['layer2', 'layer3']:\n",
    "    embedding_vectors = embedding_concat(embedding_vectors, test_outputs[layer_name])\n",
    "\n",
    "# randomly select d dimension\n",
    "embedding_vectors = torch.index_select(embedding_vectors, 1, idx)\n",
    "\n",
    "# calculate distance matrix\n",
    "B, C, H, W = embedding_vectors.size()\n",
    "embedding_vectors = embedding_vectors.view(B, C, H * W).numpy()\n",
    "dist_list = []\n",
    "for i in range(H * W):\n",
    "    mean = train_outputs[0][:, i]\n",
    "    conv_inv = np.linalg.inv(train_outputs[1][:, :, i])\n",
    "    dist = [mahalanobis(sample[:, i], mean, conv_inv) for sample in embedding_vectors]\n",
    "    dist_list.append(dist)\n",
    "\n",
    "dist_list = np.array(dist_list).transpose(1, 0).reshape(B, H, W)\n",
    "\n",
    "# upsample\n",
    "dist_list = torch.tensor(dist_list)\n",
    "score_map = F.interpolate(dist_list.unsqueeze(1), size=x.size(2), mode='bilinear',\n",
    "                            align_corners=False).squeeze().numpy()\n",
    "\n",
    "# apply gaussian smoothing on the score map\n",
    "for i in range(score_map.shape[0]):\n",
    "    score_map[i] = gaussian_filter(score_map[i], sigma=4)\n",
    "\n",
    "# Normalization\n",
    "max_score = score_map.max()\n",
    "min_score = score_map.min()\n",
    "scores = (score_map - min_score) / (max_score - min_score)\n",
    "\n",
    "# calculate image-level ROC AUC score\n",
    "img_scores = scores.reshape(scores.shape[0], -1).max(axis=1)\n",
    "\n",
    "# Store scores and filenames\n",
    "for filename, score in zip(filenames_list, img_scores):\n",
    "    scores_list.append((filename, score))\n",
    "    \n",
    "y_pred_anomaly = scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_pred_anomaly is a list of tuples like [(filename1, prob1), (filename2, prob2), ...]\n",
    "anomaly_dict = {filename: prob for filename, prob in y_pred_anomaly}\n",
    "\n",
    "df1 = pd.read_csv(\"/Users/nicolasthiou/Desktop/DataChallenge/data_challenge/PRED1.csv\")\n",
    "df2 = pd.read_csv(\"/Users/nicolasthiou/Desktop/DataChallenge/data_challenge/PRED2.csv\")\n",
    "test_df = pd.read_csv('/Users/nicolasthiou/Desktop/DataChallenge/Y_random_nKwalR1.csv')\n",
    "\n",
    "new_rows = []\n",
    "threshold = 0.5\n",
    "\n",
    "# Loop through each row in df1\n",
    "for i in range(len(df1)):\n",
    "    filename = df1.iloc[i]['filename']  # Get the filename from df1\n",
    "    p_missing = df1.iloc[i]['probabilities']  # Probability of missing from df1\n",
    "    p_drift = anomaly_dict.get(filename, 0)  # Access p_drift from the anomaly_dict based on filename\n",
    "    \n",
    "    # Get the string of probabilities and clean it up (remove brackets and split by commas)\n",
    "    p_classes_str = df2.iloc[i]['probabilities']  # Class probabilities from df2\n",
    "    p_classes_str = p_classes_str.strip('[]')  # Remove the brackets\n",
    "    p_classes = np.array([float(x) for x in p_classes_str.split(',')])  # Convert to list of floats\n",
    "\n",
    "    # Find the row in test_df that matches the filename\n",
    "    test_row = test_df[test_df['filename'] == filename]\n",
    "    if not test_row.empty:\n",
    "        window = test_row.iloc[0]['window']  # Extract 'window' value\n",
    "        lib = test_row.iloc[0]['lib']  # Extract 'lib' value\n",
    "\n",
    "        # Decide the label based on the conditions\n",
    "        if p_missing > 0.9:\n",
    "            label = 4\n",
    "        elif p_drift > threshold:\n",
    "            label = 6\n",
    "        else:\n",
    "            label = np.argmax(p_classes)  # Use argmax to get the index of the max\n",
    "\n",
    "        # Append the new row with the results\n",
    "        new_rows.append([i, filename, window, lib, label])\n",
    "\n",
    "# Create a pandas DataFrame with the results\n",
    "final_df = pd.DataFrame(new_rows, columns=['', 'filename', 'window', 'lib', 'Label'])\n",
    "\n",
    "# Save the final CSV\n",
    "final_df.to_csv('Final_grosse_archi.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
